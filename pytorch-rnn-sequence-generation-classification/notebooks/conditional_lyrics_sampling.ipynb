{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_characters = string.printable\n",
    "number_of_characters = len(all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = [\n",
    "'ABBA',\n",
    "'Ace Of Base',\n",
    "'Aerosmith',\n",
    "'Avril Lavigne',\n",
    "'Backstreet Boys',\n",
    "'Bob Marley',\n",
    "'Bon Jovi',\n",
    "'Britney Spears',\n",
    "'Bruno Mars',\n",
    "'Coldplay',\n",
    "'Def Leppard',\n",
    "'Depeche Mode',\n",
    "'Ed Sheeran',\n",
    "'Elton John',\n",
    "'Elvis Presley',\n",
    "'Eminem',\n",
    "'Enrique Iglesias',\n",
    "'Evanescence',\n",
    "'Fall Out Boy',\n",
    "'Foo Fighters',\n",
    "'Green Day',\n",
    " 'HIM',\n",
    " 'Imagine Dragons',\n",
    " 'Incubus',\n",
    " 'Jimi Hendrix',\n",
    " 'Justin Bieber',\n",
    " 'Justin Timberlake',\n",
    "'Kanye West',\n",
    " 'Katy Perry',\n",
    " 'The Killers',\n",
    " 'Kiss',\n",
    " 'Lady Gaga',\n",
    " 'Lana Del Rey',\n",
    " 'Linkin Park',\n",
    " 'Madonna',\n",
    " 'Marilyn Manson',\n",
    " 'Maroon 5',\n",
    " 'Metallica',\n",
    " 'Michael Bolton',\n",
    " 'Michael Jackson',\n",
    " 'Miley Cyrus',\n",
    " 'Nickelback',\n",
    " 'Nightwish',\n",
    " 'Nirvana',\n",
    " 'Oasis',\n",
    " 'Offspring',\n",
    " 'One Direction',\n",
    " 'Ozzy Osbourne',\n",
    " 'P!nk',\n",
    " 'Queen',\n",
    " 'Radiohead',\n",
    " 'Red Hot Chili Peppers',\n",
    " 'Rihanna',\n",
    " 'Robbie Williams',\n",
    " 'Rolling Stones',\n",
    " 'Roxette',\n",
    " 'Scorpions',\n",
    " 'Snoop Dogg',\n",
    " 'Sting',\n",
    " 'The Script',\n",
    " 'U2',\n",
    " 'Weezer',\n",
    " 'Yellowcard',\n",
    " 'ZZ Top']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_to_label(character):\n",
    "    \"\"\"Returns a one-hot-encoded tensor given a character.\n",
    "    \n",
    "    Uses string.printable as a dictionary.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    character : str\n",
    "        A character\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    one_hot_tensor : Tensor of shape (1, number_of_characters)\n",
    "        One-hot-encoded tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    character_label = all_characters.find(character)\n",
    "        \n",
    "    return character_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_labels(character_string):\n",
    "    \n",
    "    return map(lambda character: character_to_label(character), character_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes, num_conditions, n_layers=2):\n",
    "        \n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.n_layers = n_layers\n",
    "        self.num_conditions = num_conditions\n",
    "        \n",
    "        # Converts labels into one-hot encoding and runs a linear\n",
    "        # layer on each of the converted one-hot encoded elements\n",
    "        \n",
    "        # input_size -- size of the dictionary + 1 (accounts for padding constant)\n",
    "        self.characters_encoder = nn.Embedding(input_size, hidden_size)\n",
    "        \n",
    "        self.conditions_encoder = nn.Embedding(num_conditions, hidden_size)\n",
    "        \n",
    "        self.lstm = nn.LSTM(hidden_size * 2, hidden_size, n_layers)\n",
    "        \n",
    "        self.logits_fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    \n",
    "    def forward(self, input_sequences, input_sequences_conditions, input_sequences_lengths, hidden=None):\n",
    "        \n",
    "        batch_size = input_sequences.shape[1]\n",
    "\n",
    "        characters_encoded = self.characters_encoder(input_sequences)\n",
    "        conditions_endoded = self.conditions_encoder(input_sequences_conditions)\n",
    "        \n",
    "        encodings_combined = torch.cat((characters_encoded, conditions_endoded), dim=2)\n",
    "\n",
    "        # Here we run rnns only on non-padded regions of the batch\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(encodings_combined, input_sequences_lengths)\n",
    "        outputs, hidden = self.lstm(packed, hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) # unpack (back to padded)\n",
    "        \n",
    "        logits = self.logits_fc(outputs)\n",
    "        \n",
    "        logits = logits.transpose(0, 1).contiguous()\n",
    "        \n",
    "        logits_flatten = logits.view(-1, self.num_classes)\n",
    "        \n",
    "        return logits_flatten, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_size=len(all_characters) + 1,\n",
    "                         hidden_size=512,\n",
    "                         num_classes=len(all_characters),\n",
    "                         num_conditions=len(artists))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (characters_encoder): Embedding(101, 512)\n",
       "  (conditions_encoder): Embedding(64, 512)\n",
       "  (lstm): LSTM(1024, 512, num_layers=2)\n",
       "  (logits_fc): Linear(in_features=512, out_features=100)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.load_state_dict(torch.load('models/conditional_lyrics_rnn.pth'))\n",
    "\n",
    "rnn.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_rnn_conditionally(starting_sting=\"Why\", sample_length=300, temperature=1, artist_label=0):\n",
    "    \n",
    "    sampled_string = starting_sting\n",
    "    hidden = None\n",
    "\n",
    "    first_input = torch.LongTensor( string_to_labels(starting_sting) ).cuda()\n",
    "    first_input = first_input.unsqueeze(1)\n",
    "\n",
    "    # Expand the artist label to have the same size as input sequence\n",
    "    # we duplicate it in every input\n",
    "    artist_label_input = torch.LongTensor([artist_label]).expand_as(first_input)\n",
    "\n",
    "    current_sequence_input = Variable(first_input)\n",
    "    current_artist_input = Variable(artist_label_input.cuda())\n",
    "\n",
    "    output, hidden = rnn(current_sequence_input, current_artist_input, [len(sampled_string)], hidden=hidden)\n",
    "\n",
    "    output = output[-1, :].unsqueeze(0)\n",
    "\n",
    "    for i in xrange(sample_length):\n",
    "\n",
    "        output_dist = nn.functional.softmax( output.view(-1).div(temperature) ).data\n",
    "\n",
    "        predicted_label = torch.multinomial(output_dist, 1)\n",
    "\n",
    "        sampled_string += all_characters[int(predicted_label[0])]\n",
    "        current_sequence_input = Variable(predicted_label.unsqueeze(1))\n",
    "\n",
    "        artist_label_input = torch.LongTensor([artist_label]).expand_as(current_sequence_input)\n",
    "        current_artist_input = Variable(artist_label_input.cuda())\n",
    "\n",
    "        output, hidden = rnn(current_sequence_input, current_artist_input, [1], hidden=hidden)\n",
    "    \n",
    "    return sampled_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/ipykernel/__main__.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh my love me and I wasn't locked again  \n",
      "With the distance and I blecked in the bedroom all day  \n",
      "Don't tell me just a new life  \n",
      "Wasn't gonna leave me alone  \n",
      "When I get to some artilliges of truth  \n",
      "I don't know what to do  \n",
      "  \n",
      "They call me when I saw you  \n",
      "They got my brains upon my heart  \n",
      "With ever\n"
     ]
    }
   ],
   "source": [
    "print(sample_from_rnn_conditionally(artist_label=artists.index(\"Queen\"),\n",
    "                                    temperature=0.5,\n",
    "                                    starting_sting=\"Oh my\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p27)",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
