{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "import sys, os\n",
    "\n",
    "import torch.utils.data as data\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "all_characters = string.printable\n",
    "number_of_characters = len(all_characters)\n",
    "\n",
    "artists = [\n",
    "'ABBA',\n",
    "'Ace Of Base',\n",
    "'Aerosmith',\n",
    "'Avril Lavigne',\n",
    "'Backstreet Boys',\n",
    "'Bob Marley',\n",
    "'Bon Jovi',\n",
    "'Britney Spears',\n",
    "'Bruno Mars',\n",
    "'Coldplay',\n",
    "'Def Leppard',\n",
    "'Depeche Mode',\n",
    "'Ed Sheeran',\n",
    "'Elton John',\n",
    "'Elvis Presley',\n",
    "'Eminem',\n",
    "'Enrique Iglesias',\n",
    "'Evanescence',\n",
    "'Fall Out Boy',\n",
    "'Foo Fighters',\n",
    "'Green Day',\n",
    " 'HIM',\n",
    " 'Imagine Dragons',\n",
    " 'Incubus',\n",
    " 'Jimi Hendrix',\n",
    " 'Justin Bieber',\n",
    " 'Justin Timberlake',\n",
    "'Kanye West',\n",
    " 'Katy Perry',\n",
    " 'The Killers',\n",
    " 'Kiss',\n",
    " 'Lady Gaga',\n",
    " 'Lana Del Rey',\n",
    " 'Linkin Park',\n",
    " 'Madonna',\n",
    " 'Marilyn Manson',\n",
    " 'Maroon 5',\n",
    " 'Metallica',\n",
    " 'Michael Bolton',\n",
    " 'Michael Jackson',\n",
    " 'Miley Cyrus',\n",
    " 'Nickelback',\n",
    " 'Nightwish',\n",
    " 'Nirvana',\n",
    " 'Oasis',\n",
    " 'Offspring',\n",
    " 'One Direction',\n",
    " 'Ozzy Osbourne',\n",
    " 'P!nk',\n",
    " 'Queen',\n",
    " 'Radiohead',\n",
    " 'Red Hot Chili Peppers',\n",
    " 'Rihanna',\n",
    " 'Robbie Williams',\n",
    " 'Rolling Stones',\n",
    " 'Roxette',\n",
    " 'Scorpions',\n",
    " 'Snoop Dogg',\n",
    " 'Sting',\n",
    " 'The Script',\n",
    " 'U2',\n",
    " 'Weezer',\n",
    " 'Yellowcard',\n",
    " 'ZZ Top']\n",
    "\n",
    "\n",
    "def character_to_label(character):\n",
    "    \"\"\"Returns a one-hot-encoded tensor given a character.\n",
    "    \n",
    "    Uses string.printable as a dictionary.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    character : str\n",
    "        A character\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    one_hot_tensor : Tensor of shape (1, number_of_characters)\n",
    "        One-hot-encoded tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    character_label = all_characters.find(character)\n",
    "        \n",
    "    return character_label\n",
    "\n",
    "\n",
    "\n",
    "def string_to_labels(character_string):\n",
    "    \n",
    "    return map(lambda character: character_to_label(character), character_string)\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes, num_conditions, n_layers=2):\n",
    "        \n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.n_layers = n_layers\n",
    "        self.num_conditions = num_conditions\n",
    "        \n",
    "        # Converts labels into one-hot encoding and runs a linear\n",
    "        # layer on each of the converted one-hot encoded elements\n",
    "        \n",
    "        # input_size -- size of the dictionary + 1 (accounts for padding constant)\n",
    "        self.characters_encoder = nn.Embedding(input_size, hidden_size)\n",
    "        \n",
    "        self.conditions_encoder = nn.Embedding(num_conditions, hidden_size)\n",
    "        \n",
    "        self.lstm = nn.LSTM(hidden_size * 2, hidden_size, n_layers)\n",
    "        \n",
    "        self.logits_fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    \n",
    "    def forward(self, input_sequences, input_sequences_conditions, input_sequences_lengths, hidden=None):\n",
    "        \n",
    "        batch_size = input_sequences.shape[1]\n",
    "\n",
    "        characters_encoded = self.characters_encoder(input_sequences)\n",
    "        conditions_endoded = self.conditions_encoder(input_sequences_conditions)\n",
    "        \n",
    "        encodings_combined = torch.cat((characters_encoded, conditions_endoded), dim=2)\n",
    "\n",
    "        # Here we run rnns only on non-padded regions of the batch\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(encodings_combined, input_sequences_lengths)\n",
    "        outputs, hidden = self.lstm(packed, hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) # unpack (back to padded)\n",
    "        \n",
    "        logits = self.logits_fc(outputs)\n",
    "        \n",
    "        logits = logits.transpose(0, 1).contiguous()\n",
    "        \n",
    "        logits_flatten = logits.view(-1, self.num_classes)\n",
    "        \n",
    "        return logits_flatten, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_size=len(all_characters) + 1,\n",
    "                         hidden_size=512,\n",
    "                         num_classes=len(all_characters),\n",
    "                         num_conditions=len(artists))\n",
    "\n",
    "\n",
    "rnn.load_state_dict(torch.load('models/conditional_lyrics_rnn.pth'))\n",
    "\n",
    "rnn.cuda()\n",
    "\n",
    "def sample_from_rnn_conditionally(starting_sting=\"Why\", sample_length=300, temperature=1, artist_label=0):\n",
    "    \n",
    "    sampled_string = starting_sting\n",
    "    hidden = None\n",
    "\n",
    "    first_input = torch.LongTensor( string_to_labels(starting_sting) ).cuda()\n",
    "    first_input = first_input.unsqueeze(1)\n",
    "\n",
    "    # Expand the artist label to have the same size as input sequence\n",
    "    # we duplicate it in every input\n",
    "    artist_label_input = torch.LongTensor([artist_label]).expand_as(first_input)\n",
    "\n",
    "    current_sequence_input = Variable(first_input)\n",
    "    current_artist_input = Variable(artist_label_input.cuda())\n",
    "\n",
    "    output, hidden = rnn(current_sequence_input, current_artist_input, [len(sampled_string)], hidden=hidden)\n",
    "\n",
    "    output = output[-1, :].unsqueeze(0)\n",
    "\n",
    "    for i in xrange(sample_length):\n",
    "\n",
    "        output_dist = nn.functional.softmax( output.view(-1).div(temperature) ).data\n",
    "\n",
    "        predicted_label = torch.multinomial(output_dist, 1)\n",
    "\n",
    "        sampled_string += all_characters[int(predicted_label[0])]\n",
    "        current_sequence_input = Variable(predicted_label.unsqueeze(1))\n",
    "\n",
    "        artist_label_input = torch.LongTensor([artist_label]).expand_as(current_sequence_input)\n",
    "        current_artist_input = Variable(artist_label_input.cuda())\n",
    "\n",
    "        output, hidden = rnn(current_sequence_input, current_artist_input, [1], hidden=hidden)\n",
    "    \n",
    "    return sampled_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniil/repos/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do you hear my soul?  \n",
      "If I could change your back  \n",
      "When you see where I belong?  \n",
      "If I had the chance I could make any strange?  \n",
      "When youre not it agree  \n",
      "I would not live the way you love me  \n",
      "  \n",
      "When I was young your drives  \n",
      "What's your days when I was young  \n",
      "What a while?  \n",
      "I wouldn't miss \n"
     ]
    }
   ],
   "source": [
    "print(sample_from_rnn_conditionally(artist_label=artists.index(\"Queen\"),\n",
    "                                    temperature=0.5,\n",
    "                                    starting_sting=\"Why\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
